# SQL_Data_Cleaning

Implemented a robust data cleaning pipeline using Python and MySQL to ensure data integrity and accuracy for a CSV dataset. Key highlights include:


<br>1.**Data Loading and Backup**: Imported CSV data into MySQL database using Python script, ensuring data integrity and backup by creating a duplicate table for restoration purposes.
<br>2.**Duplicate Identification:** Leveraged SQL's ROW_NUMBER function to identify duplicates across tables, enhancing data quality assurance measures.
<br>3.**Table Transformation:** Engineered three distinct tables from the original and backup tables, incorporating an additional column for duplicate detection, facilitating efficient data analysis.
<br>4.**Duplicate Removal:** Utilized ROW_NUMBER function to eliminate duplicate records, optimizing data cleanliness and reducing redundancy.
<br>5.**Data Standardization:** Implemented data standardization techniques such as removing extraneous spaces, converting text data types to date data types, and handling null values to ensure uniformity and consistency.
<br>6.**Column Management:** Streamlined data structure by removing unnecessary columns, enhancing database efficiency and clarity.
